---
title: "How Prompt Engine Works"
description: "Learn how to use Prompt Engine to automate tasks in your application."
---

<img
  className="mx-auto"
  src="/images/powered_groq.png"
  alt="Powered by Groq"
  height="300"
  width="300"
/>

JigsawStack Prompt Engine is a powerful AI SDK designed to integrate into any backend, automating tasks such as web scraping, optical character recognition (OCR), translation, and more, using custom fine-tuned models. By plugging JigsawStack into your existing application infrastructure, you can offload the heavy lifting and focus on building.

The JigsawStack Prompt Engine is powered by the [Groq](https://groq.com/) LPU Inference Engine to deliver an exceptionally efficient workflow optimized for real-time performance. By leveraging Groq in the backend for fast inference and low latency, the JigsawStack Prompt Engine provides rapid results for your AI applications.

Packed with a range of built-in features, Prompt Engine makes working with LLMs effortless and efficient:

- üåê Prompt caching for repeated prompt runs
- üí¨ Automatic prompt optimization for improved performance
- üìÑ Response schema validation for accuracy and consistency
- üîÅ Reusable prompts to streamline your workflow
- üß† Multi-agent LLM from 50+ models for flexibility depending on your apps
- üö´ No virtual rate limits, tokens, and GPU management

## How does it work?

<img
  className="block"
  src="https://res.cloudinary.com/dev-ninja/image/upload/v1725312772/run_prompt_ik1g6e.png"
  alt="JigsawStack Prompt Engine workflow"
/>

The JigsawStack Prompt Engine is based on a Mixture-of-Agents (MoA) approach. Each time a prompt is executed, it is run across 5 LLMs under the hood, including LLMs powered by Groq for lightning-fast inference speed and performance, such as:

- `llama-3.1-70b-versatile`
- `llama-3.1-8b-instant`
- `mixtral-8x7b-32768`

The output of each LLM is then ranked by a smaller model based on similarity and quality before being merged into a single output.

The JigsawStack Prompt Engine especially works well if you run the same base prompt repeatedly to allow the engine to self-tune for running the best model every single time with the built-in prompt caching feature.

Optionally each prompt execution is first ran through `llama-guard-3-8b` to detect and filter for common abuse such as prompt injection, crimes, sexual content and more. Prompt guard is a feature that‚Äôs built into every step of the Prompt Engine and is configurable to allow or block specific content types.

<Info>
  Learn more about [how prompt engine works
  here](https://jigsawstack.com/blog/jigsawstack-mixture-of-agents-moa-outperform-any-single-llm-and-reduce-cost-with-prompt-engine)
</Info>

## Getting Started

### Prerequisite

- Create a [free JigsawStack account](https://jigsawstack.com/auth)
- Generate a secret key from the dashboard and securely store it

### Installation

<CodeGroup>

```bash JavaScript
npm i jigsawstack
```

```bash Python
pip install jigsawstack
```

</CodeGroup>

### Usage

You can get a JigsawStack API key by creating an account [here](https://jigsawstack.com/auth). Store the key in a secure environment like a `.env` file.

#### Creating a prompt engine:

<CodeGroup>

```javascript JavaScript
import { JigsawStack } from "jigsawstack";

const jigsaw = JigsawStack({ apiKey: "your-api-key" });

const result = await jigsaw.prompt_engine.create({
  prompt: "How to cook {dish}",
  inputs: [{ key: "dish" }],
  return_prompt: [
    {
      step: "step counter",
      instructions: "details of this step",
    },
  ],
});
```

```python Python
from jigsawstack import JigsawStack

jigsaw = JigsawStack(api_key="your-api-key")

params = {
    "prompt": "How to cook {dish}",
    "inputs": [{ "key": "dish" }],
    "return_prompt": "Return the result in a markdown format",
}

result = jigsaw.prompt_engine.create(params)
```

</CodeGroup>

<Note>
  All prompts are stored allowing you to rerun them with just the prompt ID
</Note>

#### Running the prompt:

<CodeGroup>

```javascript JavaScript
const resp = await jigsaw.prompt_engine.run({
  id: result.prompt_engine_id,
  input_values: {
    dish: "Singaporean chicken rice",
  },
});
```

```python Python
resp = jigsaw.prompt_engine.run(
    {
        "id": result.prompt_engine_id,
        "input_values": {
            "about": "Singaporean chicken rice",
        },
    }
)
```

</CodeGroup>

#### Running a prompt directly:

<CodeGroup>

```javascript JavaScript
const result = await jigsaw.prompt_engine.run_prompt_direct({
  prompt: "Tell me a story about {about}",
  inputs: [
    {
      key: "about",
      optional: false,
      initial_value: "Leaning Tower of Pisa",
    },
  ],
  return_prompt: "Return the result in a markdown format",
});
```

```python Python
params = {
    "prompt": "Tell me a story about {about}",
    "inputs": [
        {
            "key": "about",
            "optional": False,
            "initial_value": "Leaning Tower of Pisa",
        },
    ],
    "return_prompt": "Return the result in a markdown format",
}

result = jigsaw.prompt_engine.run_prompt_direct(params)
```

</CodeGroup>

<Info>
  You can learn more about the [Prompt Engine in the
  docs](https://docs.jigsawstack.com/api-reference/prompt-engine/create)
</Info>

## Llama Guard 3 by Groq

The prompt engine comes with prompt guards to prevent prompt injection from user inputs and a wide range of unsafe use cases. This can be turned on automatically using the `prompt_guard` field.

<CodeGroup>

```javascript JavaScript
const result = await jigsaw.prompt_engine.run_prompt_direct({
  prompt: "Tell me a story about {about}",
  inputs: [
    {
      key: "about",
      optional: false,
      initial_value: "Leaning Tower of Pisa",
    },
  ],
  return_prompt: "Return the result in a markdown format",
  prompt_guard: ["sexual_content", "defamation"],
});
```

```python Python
params = {
    "prompt": "Tell me a story about {about}",
    "inputs": [
        {
            "key": "about",
            "optional": False,
            "initial_value": "Leaning Tower of Pisa",
        },
    ],
    "return_prompt": "Return the result in a markdown format",
    "prompt_guard": ["sexual_content", "defamation"]
}

result = jigsaw.prompt_engine.run_prompt_direct(params)
```

</CodeGroup>
### Prompt Guard Categories

- `defamation`: Guards against potentially libelous content
- `privacy`: Protects personal information
- `hate`: Filters out discriminatory content
- `sexual_content`: Blocks explicit material
- `elections`: Prevents election misinformation
- `code_interpreter_abuse`: Guards against code exploitation
- `indiscriminate_weapons`: Blocks content about mass destruction weapons
- `specialized_advice`: Prevents unauthorized professional advice

By implementing prompt guard, you can create more secure, reliable, and user-friendly AI-powered applications. It's an invaluable tool for developers looking to harness the power of AI while maintaining control over the content generated and processed by their applications.

<Info>
  For the most up-to-date list of prompt guard options and detailed usage, refer
  to the [full
  documentation](https://docs.jigsawstack.com/api-reference/prompt-engine/create).
</Info>
