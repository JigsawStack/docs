---
title: "NSFW"
description: "Learn how use the NSFW API to detect in appropriate images"
---

Introduction

Not Safe For Work (NSFW) refers to content that includes explicit, graphic, or sensitive material, such as nudity, strong language, or violence. The JigsawStack NSFW API efficiently detects and categorizes such content, ensuring safer content usage and management.

## Initial requirements

- Setup a JigsawStack account (if you don't have an account already)
- Get your API key from [here](https://jigsawstack.com/dashboard).
- Install the [Node.js SDK](https://docs.jigsawstack.com/quick-start/node/introduction)

### Check a file

<CodeGroup>

```javascript node.js
import { JigsawStack } from "jigsawstack";

const jigsawstack = JigsawStack({
  apiKey: "your-api-key",
});

const url = "<the-image-url>";
const result = await jigsawstack.validate.nsfw(url);

console.log(result);
```

</CodeGroup>

### Sample result

```javascript
{
  success: true,
  nsfw: false,
  nudity: false,
  gore: false,
  nudity_score: 0.005777647718787193,
  nsfw_score: 0.004729619482532144,
  gore_score: 0.003681591246277094
}
```
